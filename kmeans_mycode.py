# -*- coding: utf-8 -*-
"""Kmeans_Mycode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lzAX5Bs-hwMcF4U4y65PJqjObmx-zKUM
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn.cluster import KMeans

df=pd.read_csv("/Wholesale customers data.csv")
df.head()

df.describe()
'''There is a lot of variation in the magnitude of the data. Variables like Channel and Region have low magnitude whereas variables like Fresh, Milk, Grocery, etc. have a higher magnitude.

Since K-Means is a distance-based algorithm, this difference of magnitude can create a problem. So letâ€™s first bring all the variables to the same magnitude'''

# standardizing the data
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df)

# statistics of scaled data
a=pd.DataFrame(df_scaled)
a.describe()
# df_scaled return numpy array not dataframe
#if data was already scaled, then we would just do df[:] to convert into array of all rows and columns

# defining the kmeans function with initialization as k-means++
kmeans = KMeans(n_clusters=2, init='k-means++',n_init=10)

# fitting the k means algorithm on scaled data
kmeans.fit(df_scaled) #not usaing the dataframe but the array

kmeans.inertia_
#Inertia measures how well a dataset was clustered by K-Means. A good model is one with low inertia AND a low number of clusters ( K ).
#its also called SSE. It calculates the sum of the distances of all points within a cluster from the centroid of the point.

SSE = []
for cluster in range(1,20):
    kmeans = KMeans( n_clusters = cluster, init='k-means++',n_init=10)
    kmeans.fit(df_scaled)
    SSE.append(kmeans.inertia_)
print(SSE)

frame = pd.DataFrame({'Cluster':range(1,20), 'SSE':SSE})
plt.figure(figsize=(12,6))
plt.plot(frame['Cluster'], frame['SSE'], marker='o')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')

# k means using 5 clusters and k-means++ initialization
kmeans = KMeans(n_clusters = 5, init='k-means++',n_init=10)
kmeans.fit(df_scaled)
pred = kmeans.predict(df_scaled)
pred

df.insert(8, "Clusters", pred) #adding cluster number to our dataframe before the last column
df.head(10)

# Final locations of the centroid
kmeans.cluster_centers_

# The number of iterations required to converge
kmeans.n_iter_

